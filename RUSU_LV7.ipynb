{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mihox1/RUAP-LV2/blob/main/RUSU_LV7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sijamsko učenje\n",
        "\n",
        "Sijamsko učenje (*siamese learning*) je tehnika u strojnom učenju koja koristi paralelne neuronske mreže sa zajedničkim težinama kako bi naučile efikasnu reprezentaciju ulaznih podataka. Osnovna ideja sijamskog učenja je omogućiti mreži učenje sličnosti (*similarity learning*) između parova ulaznih primjera. Primjene uključuju prepoznavanje lica, prepoznavanje otiska prsta, verifikacija potpisa, grupiranje podataka, praćenje objekata u video zapisima itd.\n",
        "\n",
        "Sijamska mreža sastoji se od dvije identične mreže koje dijele težine. Te mreže primaju različite ulaze te generiraju reprezentacije u nižedimenzionlanom prostori (*embeddings*) za svaki od ulaza. Zatim se mjeri udaljenost između *embeddinga*.\n",
        "\n",
        "Prilikom treninga mreža treba naučiti generirati takve reprezentacije da je za ulaze iste klase (pozitivni parovi) udaljenost između reprezentacija mala, a za ulaze različitih klasa (negativni parovi) udaljenost između reprezentacija veća."
      ],
      "metadata": {
        "id": "oDvZZPYMRup9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kontrastni gubitak (*constrastive loss*)\n",
        "\n",
        "Kontrastni gubitak definiran je na sljedeći način:\n",
        "$$L(x_1, x_2) = y * d(f(x_1), f(x_2))^2 + (1 - y) * max(0, m^2 - d(f(x_1), f(x_2))^2)$$\n",
        "\n",
        "$y$ je 1 ako su ulazne slike iste klase, 0 inače. $d(f(x_1), f(x_2))$ predstavlja udaljenost između *embeddinga* ulaznih slika. $m$ je proizvoljno odabrana margina, ako nam je udaljenost između reprezentacija negativnih parova veća od $m^2$, vrijednost funkcije gubitka će biti 0.\n",
        "\n",
        "Za mjeru udaljenosti se može koristiti L2 udaljenost:\n",
        "$$d(a, b) = \\sqrt{\\sum_{i=1}^n{(a_i - b_i)^2}}$$\n",
        "\n",
        "Kako bi udaljenost između reprezentacija bila ograničena, često se reprezentacije normaliziraju. Na ovaj način će sve reprezentacije biti točke na jediničnoj kružnici. Normiranje vektora:\n",
        "$$v_{norm} = \\frac{v}{||v||_2}$$"
      ],
      "metadata": {
        "id": "dnj7Avxylj8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Podatkovni skup\n",
        "\n",
        "Podatkovni skupovi za primjene za koje se koristi sijamsko učenje često imaju velik broj klasa i mali broj primjera za svaku klasu, stoga bi se nasumičnim odabiranjem parova dobio jako velik broj negativnih parova. Zbog ovoga bi mreža vrlo teško naučila raditi s pozitivnim parovima. Jedan od načina da se ovo riješi je da se generira takav podatkovni skup gdje je podjednak broj pozitivnih i negativnih parova.\n",
        "\n",
        "U nastavku je implementirano generiranje jednog ovakvog podatkovnog skupa na temelju [Omniglot](https://pytorch.org/vision/main/generated/torchvision.datasets.Omniglot.html) podatkovnog skupa."
      ],
      "metadata": {
        "id": "HRPrZlbDn6BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing useful libraries\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from imageio.v2 import imread\n",
        "%matplotlib inline\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "T5PQuVBZwGCI",
        "outputId": "c58d6e18-24ca-4345-8861-e238d2f68c4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "087RYrMDwR_C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class MatchedDataset(Dataset):\n",
        "  def __init__(self, original_dataset):\n",
        "    self.grouped = {}\n",
        "    self.size = len(original_dataset)\n",
        "    for i, c in original_dataset:\n",
        "      if c not in self.grouped:\n",
        "        self.grouped[c] = []\n",
        "      self.grouped[c].append(i)\n",
        "\n",
        "    self.classes = list(self.grouped.keys())\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    cls0 = random.choice(self.classes)\n",
        "    image0_idx = random.randint(0, len(self.grouped[cls0]) - 1)\n",
        "    image0 = self.grouped[cls0][image0_idx]\n",
        "    ## select random label, 1 for same class, 0 for different class\n",
        "    label = random.randint(0,1)\n",
        "    if label:\n",
        "      ## select a different image of the same class\n",
        "      while True:\n",
        "        image1_idx = random.randint(0, len(self.grouped[cls0]) - 1)\n",
        "        if image0_idx != image1_idx:\n",
        "          image1 = self.grouped[cls0][image1_idx]\n",
        "          break\n",
        "    else:\n",
        "      ## select a random image from a different class\n",
        "      while True:\n",
        "        cls1 = random.choice(self.classes)\n",
        "        if cls0 != cls1:\n",
        "          image1 = random.choice(self.grouped[cls1])\n",
        "          break\n",
        "\n",
        "    return image0, image1, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.size"
      ],
      "metadata": {
        "id": "IDzKW4h53TVS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W0w3K3ykMyDX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Omniglot\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_original_dataset = Omniglot(root='./data/Omniglot', download=True, background=True, transform=img_transform)\n",
        "train_dataset = MatchedDataset(train_original_dataset)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_original_dataset = Omniglot(root='./data/Omniglot', download=True, background=False, transform=img_transform)\n",
        "test_dataset = MatchedDataset(test_original_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(next(iter(train_dataloader))[0][0].numpy().transpose(1, 2, 0))"
      ],
      "metadata": {
        "id": "82mdhjxKwT14",
        "outputId": "00c656a3-8840-456a-ba1b-53dd1ab0e017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ef96795b130>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zadaci\n",
        "\n",
        "1. Proučite podatkovni skup, prikažite primjere pozitivnih i negativnih parova.\n",
        "\n",
        "2. Prilagodite neuronsku mrežu iz 3. laboratorijske vježbe kako bi primala dvije slike iz Omniglot podatkovnog skupa i generirala reprezentacije tih ulaza. Za ovo je potrebno izbaciti posljednji, klasifikacijski, sloj te uklonite aktivacijsku funkciju novog posljednjeg sloja. Izlaze iz posljednjeg sloja [normalizirajte](https://pytorch.org/docs/stable/generated/torch.nn.functional.normalize.html).\n",
        "\n",
        "3. Implementirajte funkciju kontrastnog gubitka.\n",
        "\n",
        "4. Implementirajte funkciju za treniranje te trenirajte mrežu.\n",
        "\n",
        "5. Evaluirajte istreniranu mrežu na podacima za testiranje. Funkcija za evaluaciju treba računati točnost, preciznost i odziv. Prilikom evaluacije, potrebno je odabrati prag minimalne udaljenosti za koje će ulazne slike biti klasificirane kao različite. Evaluirajte mrežu s različitim vrijednostima te skicirajte vrijednosti točnosti, preciznosti i odziva u ovisnosti o pragu. Pomoću ove krivulje, odaberite optimalnu vrijednost praga za klasifikaciju."
      ],
      "metadata": {
        "id": "D1Ub3qVvp_-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def contrastive_loss(device, m=1):\n",
        "    def loss(embedding1, embedding2, label):\n",
        "        d = F.pairwise_distance(embedding1, embedding2)\n",
        "\n",
        "        loss_contrastive = torch.mean((1 - label) * torch.pow(d, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(m - d, min=0.0), 2))\n",
        "\n",
        "        return loss_contrastive\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "ocLdX6AeV8Hs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_module = contrastive_loss(device, 1)"
      ],
      "metadata": {
        "id": "5mQ4gzxZPCZ5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Check if you implemented the loss correctly, the correct output should be 0.2750\n",
        "\n",
        "loss_module(torch.Tensor([[1, 1, 1], [0, 1, 1]]).to(device), torch.Tensor([[1, 0.8, 0.9], [0, 0.5, 0.5]]).to(device), torch.Tensor([1, 0]).to(device))"
      ],
      "metadata": {
        "id": "L3zViDb0u6Rd",
        "outputId": "cc476c27-2edf-4660-bb72-51d5601b43c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5514, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(thresholds, results):\n",
        "  # thresholds is an array of values of the threshold, e.g. np.arange(0, 2, 0.1)\n",
        "  # results is an array of shape (len(thresholds), 3) where\n",
        "  # results[:,0] is the values of accuracy given the different thresholds\n",
        "  # and results[:,1] and results[:,2] are similarly values of precision and recall\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(thresholds, results[:,0], c='green', label='accuracy')\n",
        "  ax.plot(thresholds, results[:,1], c='blue', label='precision')\n",
        "  ax.plot(thresholds, results[:,2], c='orange', label='recall')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "NsiszX0nK8Hx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(model, dataloader, n = 6):\n",
        "  ## visualize some examples of input pairs and the distance between their embeddings\n",
        "  fig = plt.figure(constrained_layout=True, figsize=(4, 2.2*n))\n",
        "  subfigs = fig.subfigures(nrows=n, ncols=1)\n",
        "\n",
        "  for i in range(n):\n",
        "    data = next(iter(dataloader))\n",
        "    data_inputs1 = data[0][i].unsqueeze(0)\n",
        "    data_inputs2 = data[1][i].unsqueeze(0)\n",
        "    data_labels = data[2][i].unsqueeze(0)\n",
        "\n",
        "    data_inputs1 = data_inputs1.to(device)\n",
        "    data_inputs2 = data_inputs2.to(device)\n",
        "    data_labels = data_labels.to(device)\n",
        "\n",
        "    embedding1, embedding2 = model((data_inputs1, data_inputs2))\n",
        "    dist = torch.linalg.norm(embedding1 - embedding2, dim = 1)\n",
        "\n",
        "    subfig = subfigs[i]\n",
        "    subfig.suptitle('Distance: %.4f, Label: %d'%(dist, data_labels), size='small')\n",
        "    ax = subfig.subplots(nrows=1, ncols=2)\n",
        "    img1_ = data_inputs1[0].cpu().numpy().transpose(1, 2, 0)\n",
        "    ax[0].imshow(img1_)\n",
        "    img2_ = data_inputs2[0].cpu().numpy().transpose(1, 2, 0)\n",
        "    ax[1].imshow(img2_)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "sQKctD-2S3jX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DNgh7rsuqVc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}